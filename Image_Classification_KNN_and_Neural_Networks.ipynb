{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Image_Classification_KNN_and_Neural_Networks.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "WIMID1lWifoP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YsgnmrEsjZOM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#import data from google drive\n",
        "from google.colab import drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a4yXmNELlpjy",
        "colab_type": "code",
        "outputId": "eebe9ef1-9219-48be-fc18-f948ddda9ba3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "cell_type": "code",
      "source": [
        "#mount the drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3Ai-7_UVluZz",
        "colab_type": "code",
        "outputId": "4fb10776-151e-4506-864a-b127ec29641a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "!ls -all './drive/My Drive/SVHN_neural_network_dataset'\n",
        " "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 480122\n",
            "-r-------- 1 root root 491644096 Oct  3 12:20 SVHN_single_grey1.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Us50jcNJrg10",
        "colab_type": "code",
        "outputId": "7e63a9ef-bb9d-4b29-f2ba-1eff0d5a8f1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "#import os to list the files available in the folder.\n",
        "#the folder below will list the directories available in the given path\n",
        "import os\n",
        "filePath = './drive/My Drive/SVHN_neural_network_dataset'\n",
        "os.listdir(filePath)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['SVHN_single_grey1.h5']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "Ng6OZw05ritH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Read the .h5 file into google colab object\n",
        "dataFile = filePath+'/'+'SVHN_single_grey1.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tXT8DUgathY9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#This import is required to read hdf5 files into python.\n",
        "#More info can be found in http://docs.h5py.org/en/latest/quick.html\n",
        "import h5py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vxfxxn1RudNd",
        "colab_type": "code",
        "outputId": "19a108e1-0e1c-4201-b516-9166fbd69e84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "#File content\n",
        "dataFile"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./drive/My Drive/SVHN_neural_network_dataset/SVHN_single_grey1.h5'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "BVGSEHZMuim7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Read the content of the file into another variable. The file will be read into the variable\n",
        "f = h5py.File(dataFile, 'r')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DyqnQmkWupKQ",
        "colab_type": "code",
        "outputId": "dee3e7f0-1c2a-4cde-9442-effd45f4ac9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Keys: %s\" % f.keys())\n",
        "a_group_key = list(f.keys())[0]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Keys: KeysView(<HDF5 file \"SVHN_single_grey1.h5\" (mode r)>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nVVJ26iAuz6B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = list(f[a_group_key])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Tiaajf-LvO3x",
        "colab_type": "code",
        "outputId": "6c54ee28-285f-425d-a46c-ebda193ceb58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "#List the keys present in the dataset\n",
        "list(f.keys())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['X_test', 'X_train', 'X_val', 'y_test', 'y_train', 'y_val']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "ze79hPwrynjr",
        "colab_type": "code",
        "outputId": "b9d1f0c5-8ce6-4025-b6e2-84274afd4483",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "cell_type": "code",
      "source": [
        "#print the keys in the dataset\n",
        "for key in f.keys():\n",
        "  print(\"Key value \",key)\n",
        "  "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Key value  X_test\n",
            "Key value  X_train\n",
            "Key value  X_val\n",
            "Key value  y_test\n",
            "Key value  y_train\n",
            "Key value  y_val\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qT-_oPHg1z3L",
        "colab_type": "code",
        "outputId": "74f1df64-be9a-49ad-e56d-b76be190e7b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "cell_type": "code",
      "source": [
        "#Get the dataset for each of the keys present in the file\n",
        "for i, key in enumerate(f.keys()):\n",
        "  print('key value is ',i+1, key)\n",
        "  X_train = f['X_train'].value\n",
        "  if(key == 'X_test'):\n",
        "    X_test = f['X_test'].value\n",
        "  if(key == 'X_val'):\n",
        "    X_val = f['X_val'].value\n",
        "  if(key == 'y_test'):\n",
        "    y_test = f['y_test'].value\n",
        "  if(key == 'y_train'):\n",
        "    y_train = f['y_train'].value\n",
        "  if(key == 'y_val'):\n",
        "    y_val = f['y_val'].value\n",
        "    \n",
        "    "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "key value is  1 X_test\n",
            "key value is  2 X_train\n",
            "key value is  3 X_val\n",
            "key value is  4 y_test\n",
            "key value is  5 y_train\n",
            "key value is  6 y_val\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8aZykva05EKj",
        "colab_type": "code",
        "outputId": "3b975ed0-0c94-4838-9054-8b0d4b97ea04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Size of various datasets extracted are \")\n",
        "print(\"X_train shape is \", X_train.shape,\", data set Dtype is \", X_train.dtype, \" ,type \", type(X_train))\n",
        "print(\"X_test shape is \", X_test.shape,\", data set Dtype is \", X_test.dtype, \" ,type \", type(X_test))\n",
        "print(\"X_val shape is \", X_val.shape,\", data set Dtype is \", X_val.dtype, \" ,type \", type(X_val))\n",
        "print(\"y_train shape is \", y_train.shape,\", data set Dtype is \", y_train.dtype, \" ,type \", type(y_train))\n",
        "print(\"y_test shape is \", y_test.shape,\", data set Dtype is \", y_test.dtype, \" ,type \", type(y_test))\n",
        "print(\"y_val shape is \", y_val.shape,\", data set Dtype is \", y_val.dtype, \" ,type \", type(y_val))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of various datasets extracted are \n",
            "X_train shape is  (42000, 32, 32) , data set Dtype is  float32  ,type  <class 'numpy.ndarray'>\n",
            "X_test shape is  (18000, 32, 32) , data set Dtype is  float32  ,type  <class 'numpy.ndarray'>\n",
            "X_val shape is  (60000, 32, 32) , data set Dtype is  float32  ,type  <class 'numpy.ndarray'>\n",
            "y_train shape is  (42000,) , data set Dtype is  uint8  ,type  <class 'numpy.ndarray'>\n",
            "y_test shape is  (18000,) , data set Dtype is  uint8  ,type  <class 'numpy.ndarray'>\n",
            "y_val shape is  (60000,) , data set Dtype is  uint8  ,type  <class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0RV8BGOZ7Jsh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sklearn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6Y5eBLUa-Dle",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn import neighbors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I1y41cYm-Nub",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cV4xgaYR-b0S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Generally the optimum way to calculate the K value is below\n",
        "#Optimum K =  sqrt(N)/2 where N is the number of samples.\n",
        "#Here we have 42000 samples and hence K = sqrt(42000)/2 = 103\n",
        "knn = KNeighborsClassifier(n_neighbors=103, weights='uniform', algorithm='auto', n_jobs = -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WtntbB1rFVXI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#The current dataset shape is three dimensional which will not cthompile when passed to ML algorithms. KNN always\n",
        "#expects a two dimensional data.\n",
        "#So, we will need to reshape data.\n",
        "#We will need to flatten the three dimensional data into two dimensional data. The number of samples shall be\n",
        "#maintained whereas The nx and ny components can be multiplied and kept as the second dimension.\n",
        "#So, (number_of_samples, nx, ny ) will be flattened out as (number_of_samples, nx*ny)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q9QkKoCYTrc7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def reshapedata(X):\n",
        "  number_of_samples, nx, ny = X.shape\n",
        "  X = X.reshape((number_of_samples, nx*ny))\n",
        "  print(X.shape)\n",
        "  return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TcSCsu5YUEm0",
        "colab_type": "code",
        "outputId": "e1ba2b4c-a41f-4c95-c99d-ad2f954f932e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "cell_type": "code",
      "source": [
        "X_train = reshapedata(X_train)\n",
        "print(\"Shape of X_train after reshaping \",X_train.shape)\n",
        "X_test = reshapedata(X_test)\n",
        "print(\"Shape of X_test after reshaping \",X_test.shape)\n",
        "X_val = reshapedata(X_val)\n",
        "print(\"Shape of X_val after reshaping \", X_val.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(42000, 1024)\n",
            "Shape of X_train after reshaping  (42000, 1024)\n",
            "(18000, 1024)\n",
            "Shape of X_test after reshaping  (18000, 1024)\n",
            "(60000, 1024)\n",
            "Shape of X_val after reshaping  (60000, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "49c8Ar3JFbW9",
        "colab_type": "code",
        "outputId": "27ce2b38-3401-4005-b035-dbbbd075498e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "#Fit KNN with training data after reshaping the data.\n",
        "knn.fit(X_train, y_train)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "           metric_params=None, n_jobs=-1, n_neighbors=103, p=2,\n",
              "           weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "08mIUpnwVsrt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_predict = knn.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ofq6MIRKYa3U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report, f1_score, confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WUZnCUtvcq8Z",
        "colab_type": "code",
        "outputId": "26b31ae6-c2e7-40ea-fdc6-0d04bd7f32f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Accuracy score %5.2f \" %(accuracy_score(y_true=y_test, y_pred=y_predict)))\n",
        "print(\"F1 score is %5.2f\" %(f1_score(y_true=y_test, y_pred=y_predict, average='weighted')))\n",
        "print(\"Classification report\")\n",
        "print(classification_report(y_test, y_predict))\n",
        "print(\"Confusion matrix \")\n",
        "print(confusion_matrix(y_test, y_predict))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score  0.53 \n",
            "F1 score is  0.53\n",
            "Classification report\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "          0       0.43      0.71      0.53      1814\n",
            "          1       0.44      0.73      0.55      1828\n",
            "          2       0.66      0.50      0.57      1803\n",
            "          3       0.51      0.43      0.47      1719\n",
            "          4       0.65      0.64      0.65      1812\n",
            "          5       0.55      0.41      0.47      1768\n",
            "          6       0.54      0.40      0.46      1832\n",
            "          7       0.67      0.63      0.65      1808\n",
            "          8       0.51      0.39      0.44      1812\n",
            "          9       0.54      0.47      0.50      1804\n",
            "\n",
            "avg / total       0.55      0.53      0.53     18000\n",
            "\n",
            "Confusion matrix \n",
            "[[1287   82   25   43   52   29   90   39   51  116]\n",
            " [ 118 1328   53   62   68   31   36   66   30   36]\n",
            " [ 105  254  906   71   61   53   31  161   60  101]\n",
            " [ 131  282   90  740   51  149   31   78   95   72]\n",
            " [ 134  251   42   56 1167   21   51   17   26   47]\n",
            " [ 179  176   47  206   58  727  119   51  118   87]\n",
            " [ 367  155   31   52  152   85  738   22  168   62]\n",
            " [ 119  193   96   66   33   35   47 1132   31   56]\n",
            " [ 273  153   46  101   96  102  183   24  703  131]\n",
            " [ 294  170   45   62   63   92   45   92   95  846]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "a3-8txIkgQor",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Let us go with neural networks to run the test cases again\n",
        "#START -----  NEURAL NETWORKS -----#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "87q0v084gdMp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Let us create a model\n",
        "model = tf.keras.models.Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ozJaDOXRonZJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Let us normalize the data\n",
        "X_train = X_train/1024\n",
        "X_test = X_test/1024\n",
        "X_val = X_val/1024"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NBkJwBGppJct",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Let us convert Y values to categorical\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
        "y_val = tf.keras.utils.to_categorical(y_val, num_classes=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KDerVulSgx2f",
        "colab_type": "code",
        "outputId": "91a7f507-2aa2-4928-e4cb-3df8dca59ded",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "#Add batch normalization\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "#Add a dense layer with 200 neurons\n",
        "tf.keras.layers.Dense(units=200, activation='relu', input_shape=(1024,))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.layers.core.Dense at 0x7fadd157d080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "0r0R5BaMiy3m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Let us add few more layers with units=100, 50, 20 and output layer with unit as 10\n",
        "model.add(tf.keras.layers.Dense(units=100, activation='relu'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Dense(units=50, activation='relu'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Dense(units=20, activation='relu'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Dense(units=10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lvjfC7v9kwss",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-1qoIak4lFEx",
        "colab_type": "code",
        "outputId": "3ff400f1-4a63-4000-a0a1-238cd1265f82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1156
        }
      },
      "cell_type": "code",
      "source": [
        "#Fit the data and execute the model\n",
        "model.fit(x=X_train, y=y_train, batch_size=64, epochs=30, validation_data=(X_val, y_val))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 42000 samples, validate on 60000 samples\n",
            "Epoch 1/30\n",
            "42000/42000 [==============================] - 9s 221us/step - loss: 2.3034 - acc: 0.1002 - val_loss: 2.3025 - val_acc: 0.1000\n",
            "Epoch 2/30\n",
            "42000/42000 [==============================] - 8s 181us/step - loss: 2.3030 - acc: 0.0999 - val_loss: 2.3026 - val_acc: 0.1000\n",
            "Epoch 3/30\n",
            "42000/42000 [==============================] - 8s 179us/step - loss: 2.0247 - acc: 0.2433 - val_loss: 1.5621 - val_acc: 0.4619\n",
            "Epoch 4/30\n",
            "42000/42000 [==============================] - 7s 177us/step - loss: 1.3611 - acc: 0.5468 - val_loss: 1.1854 - val_acc: 0.6212\n",
            "Epoch 5/30\n",
            "42000/42000 [==============================] - 8s 179us/step - loss: 1.1283 - acc: 0.6387 - val_loss: 1.0314 - val_acc: 0.6739\n",
            "Epoch 6/30\n",
            "42000/42000 [==============================] - 7s 178us/step - loss: 0.9859 - acc: 0.6926 - val_loss: 0.9329 - val_acc: 0.7098\n",
            "Epoch 7/30\n",
            "42000/42000 [==============================] - 8s 179us/step - loss: 0.8869 - acc: 0.7256 - val_loss: 0.8525 - val_acc: 0.7372\n",
            "Epoch 8/30\n",
            "42000/42000 [==============================] - 8s 179us/step - loss: 0.8160 - acc: 0.7483 - val_loss: 0.8077 - val_acc: 0.7530\n",
            "Epoch 9/30\n",
            "42000/42000 [==============================] - 8s 181us/step - loss: 0.7603 - acc: 0.7671 - val_loss: 0.7485 - val_acc: 0.7732\n",
            "Epoch 10/30\n",
            "42000/42000 [==============================] - 8s 183us/step - loss: 0.7222 - acc: 0.7791 - val_loss: 0.7103 - val_acc: 0.7843\n",
            "Epoch 11/30\n",
            "42000/42000 [==============================] - 8s 200us/step - loss: 0.6857 - acc: 0.7904 - val_loss: 0.6847 - val_acc: 0.7899\n",
            "Epoch 12/30\n",
            "42000/42000 [==============================] - 8s 180us/step - loss: 0.6556 - acc: 0.7985 - val_loss: 0.6606 - val_acc: 0.7992\n",
            "Epoch 13/30\n",
            "42000/42000 [==============================] - 8s 179us/step - loss: 0.6293 - acc: 0.8040 - val_loss: 0.6638 - val_acc: 0.7978\n",
            "Epoch 14/30\n",
            "42000/42000 [==============================] - 8s 179us/step - loss: 0.6048 - acc: 0.8130 - val_loss: 0.6384 - val_acc: 0.8042\n",
            "Epoch 15/30\n",
            "42000/42000 [==============================] - 7s 178us/step - loss: 0.5793 - acc: 0.8205 - val_loss: 0.5841 - val_acc: 0.8228\n",
            "Epoch 16/30\n",
            "42000/42000 [==============================] - 7s 178us/step - loss: 0.5623 - acc: 0.8260 - val_loss: 0.5837 - val_acc: 0.8211\n",
            "Epoch 17/30\n",
            "42000/42000 [==============================] - 8s 180us/step - loss: 0.5444 - acc: 0.8291 - val_loss: 0.5753 - val_acc: 0.8253\n",
            "Epoch 18/30\n",
            "42000/42000 [==============================] - 8s 179us/step - loss: 0.5301 - acc: 0.8348 - val_loss: 0.5389 - val_acc: 0.8362\n",
            "Epoch 19/30\n",
            "42000/42000 [==============================] - 7s 176us/step - loss: 0.5110 - acc: 0.8409 - val_loss: 0.5423 - val_acc: 0.8341\n",
            "Epoch 20/30\n",
            "42000/42000 [==============================] - 8s 179us/step - loss: 0.4966 - acc: 0.8445 - val_loss: 0.5213 - val_acc: 0.8426\n",
            "Epoch 21/30\n",
            "42000/42000 [==============================] - 7s 178us/step - loss: 0.4877 - acc: 0.8479 - val_loss: 0.5122 - val_acc: 0.8456\n",
            "Epoch 22/30\n",
            "42000/42000 [==============================] - 7s 178us/step - loss: 0.4725 - acc: 0.8511 - val_loss: 0.5089 - val_acc: 0.8457\n",
            "Epoch 23/30\n",
            "42000/42000 [==============================] - 7s 178us/step - loss: 0.4643 - acc: 0.8545 - val_loss: 0.5333 - val_acc: 0.8372\n",
            "Epoch 24/30\n",
            "42000/42000 [==============================] - 7s 176us/step - loss: 0.4518 - acc: 0.8579 - val_loss: 0.4758 - val_acc: 0.8573\n",
            "Epoch 25/30\n",
            "42000/42000 [==============================] - 7s 178us/step - loss: 0.4443 - acc: 0.8600 - val_loss: 0.4863 - val_acc: 0.8509\n",
            "Epoch 26/30\n",
            "42000/42000 [==============================] - 8s 179us/step - loss: 0.4345 - acc: 0.8628 - val_loss: 0.4656 - val_acc: 0.8597\n",
            "Epoch 27/30\n",
            "42000/42000 [==============================] - 7s 179us/step - loss: 0.4216 - acc: 0.8665 - val_loss: 0.4854 - val_acc: 0.8535\n",
            "Epoch 28/30\n",
            "42000/42000 [==============================] - 8s 180us/step - loss: 0.4148 - acc: 0.8686 - val_loss: 0.4545 - val_acc: 0.8644\n",
            "Epoch 29/30\n",
            "42000/42000 [==============================] - 8s 192us/step - loss: 0.4080 - acc: 0.8715 - val_loss: 0.4625 - val_acc: 0.8612\n",
            "Epoch 30/30\n",
            "42000/42000 [==============================] - 8s 180us/step - loss: 0.4017 - acc: 0.8732 - val_loss: 0.4686 - val_acc: 0.8590\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fadd0775eb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "id": "V8dIqG_jyuSi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TIbtG7BMy0gq",
        "colab_type": "code",
        "outputId": "2b90d68d-b3ca-44b3-cdc0-d88f49b1710d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18000/18000 [==============================] - 1s 50us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6644137847688463, 0.8145]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "metadata": {
        "id": "7SiV6yDN1MKs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Observation:\n",
        "1. Traditional ML - KNN algorithm:\n",
        "  1. The prediction took a lot of time to predict the test values which were fed into the model\n",
        "  2. The accuracy score was hovering around 53% which was very low compared with the neural network model.\n",
        "2. Neural network model - using batch normalization, RELU as activation, ADAM as optimizer\n",
        "  1. The model took less than 4 minutes to train the dataset and the prediction, evaluation was even faster, unlike KNN which took more than 10 minutes to completed\n",
        "  2. Inspite of being faster, there was no issues with accuracy and other metric parameters.\n",
        "  3. The accuracy in the train data set was 87.3%, validation set was 85.9%and the test set gave an accuracy of 81.45% which is exceedingly high compared with the traditional ML models."
      ]
    },
    {
      "metadata": {
        "id": "6Dv9G_hz3UG5",
        "colab_type": "code",
        "outputId": "427469a4-db72-4a95-9682-09d68319a7c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "#Picked from Internet - custom metrics. ----TO CHECK THIS LATER -----\n",
        "#Let us check the version of keras used.\n",
        "tf.keras.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.6-tf'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "metadata": {
        "id": "K3prHFGS4LmL",
        "colab_type": "code",
        "outputId": "f460227b-1dbc-4b97-fc8e-757376eddd00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "#Since Keras 2.0, metrics like precision, recall, f1 score have been removed from the libraries. Hence we would\n",
        "#be required to write custom metric functions for calculating them\n",
        "#The below code is copied from https://github.com/keras-team/keras/issues/5400\n",
        "\n",
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "_vV7ru0w32SJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def precision(y_true, y_pred):\n",
        "    \"\"\"Precision metric.\n",
        "\n",
        "    Only computes a batch-wise average of precision.\n",
        "\n",
        "    Computes the precision, a metric for multi-label classification of\n",
        "    how many selected items are relevant.\n",
        "    \"\"\"\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def recall(y_true, y_pred):\n",
        "    \"\"\"Recall metric.\n",
        "\n",
        "    Only computes a batch-wise average of recall.\n",
        "\n",
        "    Computes the recall, a metric for multi-label classification of\n",
        "    how many relevant items are selected.\n",
        "    \"\"\"\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "\n",
        "def f1(y_true, y_pred):\n",
        "    def recall(y_true, y_pred):\n",
        "        \"\"\"Recall metric.\n",
        "\n",
        "        Only computes a batch-wise average of recall.\n",
        "\n",
        "        Computes the recall, a metric for multi-label classification of\n",
        "        how many relevant items are selected.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "    def precision(y_true, y_pred):\n",
        "        \"\"\"Precision metric.\n",
        "\n",
        "        Only computes a batch-wise average of precision.\n",
        "\n",
        "        Computes the precision, a metric for multi-label classification of\n",
        "        how many selected items are relevant.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}